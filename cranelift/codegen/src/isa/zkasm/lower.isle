;; zkasm instruction selection and CLIF-to-MachInst lowering.

;; The main lowering constructor term: takes a clif `Inst` and returns the
;; register(s) within which the lowered instruction's result values live.
(decl partial lower (Inst) InstOutput)

;;;; Rules for `iconst` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type ty (iconst (u64_from_imm64 n))))
  (imm ty n))

;;;; Rules for `f32const` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (f32const (u32_from_ieee32 n)))
  (imm $F32 n))

;;;; Rules for `f64const` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (f64const (u64_from_ieee64 n)))
  (imm $F64 n))

;;;; Rules for `null` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type ty (null)))
  (imm ty 0))


;;;; Rules for `iadd` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; Base case, simply adding things in registers.
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (iadd x y)))
  (rv_add x y))

(rule 1 (lower (has_type $I32 (iadd x y)))
  (gen_andi (rv_add x y) 0xFFFFFFFF))

;; Hint 1: imm31 should work
;; (rule 1 (lower (iadd (imm32_from_value x) (imm32_from_value y)))
;;   (zk_add x y))

;; Fused Multiply Accumulate Rules `vmacc`
;;
;; I dont think we can use `vmadd`/`vmnsub` here since it just modifies the multiplication
;; register instead of the addition one. The actual pattern matched seems to be
;; exactly the same.

;;; Rules for `uadd_overflow_trap` ;;;;;;;;;;;;;
(rule
  (lower (has_type (fits_in_64 ty) (uadd_overflow_trap x y tc)))
  (let ((res ValueRegs (lower_uadd_overflow x y ty))
        (_ InstOutput (gen_trapif (value_regs_get res 1) tc)))
    (value_regs_get res 0)))


;;;; Rules for `isub` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Base case, simply subtracting things in registers.

(rule (lower (has_type (ty_int_ref_scalar_64 ty) (isub x y)))
  (rv_sub x y))

(rule 1 (lower (has_type $I32 (isub x y)))
  (gen_andi (rv_sub x y) 0xFFFFFFFF))

;;;; Rules for `ineg`/`bnot` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (ineg val))
  (let
    ((result WritableXReg (temp_writable_xreg))
      (_ Unit (emit (MInst.Ineg result (value_regs_get val 0)))))
    (output_xreg result)))

(rule (lower (bnot val))
  (let
    ((result WritableXReg (temp_writable_xreg))
      (_ Unit (emit (MInst.Bnot result (value_regs_get val 0)))))
    (output_xreg result)))

;;;; Rules for `imul` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (imul x y)))
  (zk_mul x y))

(rule 1 (lower (has_type $I32 (imul x y)))
  (gen_andi (zk_mul x y) 0xFFFFFFFF))

;;;; Rules for `smulhi` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (smulhi x y)))
  (lower_smlhi ty (sext x ty $I64) (sext y ty $I64)))

;;;; Rules for `umulhi` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (umulhi x y)))
  (lower_umlhi ty (zext x ty $I64) (zext y ty $I64)))

;;;; Rules for `div` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (udiv x y))
  (zk_divu x y))

(rule (lower (sdiv x y))
  (zk_div x y))

;;;; Rules for `rem` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (srem x y))
  (zk_rem x y))

(rule (lower (urem x y))
  (zk_remu x y))

;;;; Rules for `and` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int ty) (band x y)))
  (gen_and ty x y))

;;;; Rules for `or` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int ty) (bor x y)))
  (gen_or ty x y))

;;;; Rules for `xor` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (fits_in_64 (ty_int ty)) (bxor x y)))
  (rv_xor x y))

;;;; Rules for `bit_reverse` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;; Rules for `bswap` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 1 (lower (has_type (fits_in_64 (ty_int ty)) (bswap x)))
  (gen_bswap ty x))

;;;; Rules for `ctz` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (ctz x)))
  (lower_ctz ty x))

;;;; Rules for `clz` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (clz x)))
  (lower_clz ty x))

;;;; Rules for `uextend` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type out_ty (uextend val @ (value_type in_ty))))
  (extend val (ExtendOp.Zero) in_ty out_ty))

;;;; Rules for `sextend` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type out_ty (sextend val @ (value_type in_ty))))
  (extend val (ExtendOp.Signed) in_ty out_ty))

;; The instructions below are present in RV64I and sign-extend the result to 64 bits.

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (iadd x y)))))
  (rv_addw x y))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (isub x y)))))
  (rv_subw x y))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (ushr x y)))))
  (rv_srlw x (value_regs_get y 0)))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (sshr x y)))))
  (rv_sraw x (value_regs_get y 0)))

;;;; Rules for `popcnt` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule 0 (lower (has_type (fits_in_64 ty) (popcnt x)))
  (gen_popcnt (zext x ty $I64) ty))

;;;; Rules for `ishl` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type $I64 (ishl x y)))
  (zk_shl x (gen_andi y 0x3F)))

(rule (lower (has_type $I32 (ishl x y)))
  (gen_andi (zk_shl x (gen_andi y 0x1F)) 0xFFFFFFFF))

;;;; Rules for `ushr` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type $I64 (ushr x y)))
  (zk_shr_u x (gen_andi y 0x3F)))

(rule (lower (has_type $I32 (ushr x y)))
  (gen_andi (zk_shr_u x (gen_andi y 0x1F)) 0xFFFFFFFF))

;;;; Rules for `sshr` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; 8/16 bit types need a mask on the shift amount, and the LHS needs to be
;; zero extended.
; (rule 0 (lower (has_type (ty_int (fits_in_16 ty)) (sshr x y)))
;   (if-let mask (u64_to_imm12 (shift_mask ty)))
;   (rv_sraw (sext x ty $I64) (rv_andi (value_regs_get y 0) mask)))

;; Using the 32bit version of `sra` automatically masks the shift amount.
(rule 1 (lower (has_type $I32 (sshr x y)))
  (rv_sraw x (value_regs_get y 0)))

;; Similarly, the 64bit version does the right thing.
(rule 1 (lower (has_type $I64 (sshr x y)))
  (rv_sra x (value_regs_get y 0)))

;;;; Rules for `rotl` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type $I64 (rotl x y)))
 (let ((shift XReg (gen_andi y 0x3F))
       (left XReg (zk_shl x shift))
       (right XReg (zk_shr_u x (rv_sub (imm $I32 64) shift))))
  (rv_or left right)))

(rule (lower (has_type $I32 (rotl x y)))
 (let ((shift XReg (gen_andi y 0x1F))
       (left XReg (zk_shl x shift))
       (right XReg (zk_shr_u x (rv_sub (imm $I32 32) shift))))
  (gen_andi (rv_or left right) 0xFFFFFFFF)))

;;;; Rules for `rotr` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (rotr x y)))
  (lower_rotr ty (zext x ty $I64) (value_regs_get y 0)))

;;;;;  Rules for `ireduce`;;;;;;;;;;;;;;;;;
(rule
  (lower (has_type ty (ireduce x)))
  (value_regs_get x 0))

;;;;;  Rules for `fpromote`;;;;;;;;;;;;;;;;;
;; TODO(akashin): Fix this rule.
(rule (lower (fpromote x))
  x)

;;;;;  Rules for `fdemote`;;;;;;;;;;;;;;;;;;
;; TODO(akashin): Fix this rule.
(rule (lower (fdemote x))
  x)

;;;;;  Rules for `stack_addr`;;;;;;;;;
(rule
  (lower (stack_addr ss offset))
  (gen_stack_addr ss offset))

;;;;;  Rules for `is_null`;;;;;;;;;

;; Null references are represented by the constant value `0`.
; (rule (lower (is_null v))
;   (rv_seqz v))

;;;;;  Rules for `is_invalid`;;;;;;;;;

;; Invalid references are represented by the constant value `-1`.
; (rule (lower (is_invalid v))
;   (rv_seqz (rv_addi v (imm12_const 1))))

;;;;;  Rules for `select`;;;;;;;;;
(rule
  (lower (has_type ty (select c @ (value_type cty) x y)))
  (gen_select ty (truthy_to_reg cty (normalize_cmp_value cty c (ExtendOp.Zero))) x y))

(rule 1
  (lower (has_type (fits_in_64 ty) (select (icmp cc a b @ (value_type (fits_in_64 in_ty))) x y)))
  (let ((a XReg (truthy_to_reg in_ty (normalize_cmp_value in_ty a (intcc_to_extend_op cc))))
        (b XReg (truthy_to_reg in_ty (normalize_cmp_value in_ty b (intcc_to_extend_op cc)))))
    (gen_select_reg cc a b x y)))

;;;;;  Rules for `bitselect`;;;;;;;;;

;; Do a (c & x) | (~c & y) operation.
; (rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (bitselect c x y)))
;   (let ((tmp_x XReg (rv_and c x))
;         (c_inverse XReg (rv_not c))
;         (tmp_y XReg (rv_and c_inverse y)))
;     (rv_or tmp_x tmp_y)))

;;;;;  Rules for `isplit`;;;;;;;;;
(rule
  (lower (isplit x))
  (let
    ((t1 XReg (value_regs_get x 0))
      (t2 XReg (value_regs_get x 1)))
    (output_pair t1 t2)))

;;;;;  Rules for `smax`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty)  (smax x y)))
  (gen_int_select ty (IntSelectOP.Smax) (ext_int_if_need $true x ty) (ext_int_if_need $true y ty)))

;;;;;  Rules for `smin`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty)  (smin x y)))
  (gen_int_select ty (IntSelectOP.Smin) (ext_int_if_need $true x ty) (ext_int_if_need $true y ty)))

;;;;;  Rules for `umax`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty)  (umax x y)))
  (gen_int_select ty (IntSelectOP.Umax) (ext_int_if_need $false x ty) (ext_int_if_need $false y ty)))

;;;;;  Rules for `umin`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty) (umin x y)))
  (gen_int_select ty (IntSelectOP.Umin) (ext_int_if_need $false x ty) (ext_int_if_need $false y ty)))

;;;;;  Rules for `debugtrap`;;;;;;;;;
(rule
  (lower (debugtrap))
  (side_effect (SideEffectNoResult.Inst (MInst.EBreak))))

;;;;;  Rules for `trap`;;;;;;;;;
(rule
  (lower (trap code))
  (udf code))

;;;;;  Rules for `resumable_trap`;;;;;;;;;
(rule
  (lower (resumable_trap code))
  (udf code))

;;;;;  Rules for `uload8`;;;;;;;;;
(rule (lower (uload8 flags addr offset))
  (gen_load (amode addr offset $I8) (LoadOP.U8) flags))

;;;;;  Rules for `sload8`;;;;;;;;;
(rule (lower (sload8 flags addr offset))
  (gen_load (amode addr offset $I8) (LoadOP.I8) flags))

;;;;;  Rules for `uload16`;;;;;;;;;
(rule (lower (uload16 flags addr offset))
  (gen_load (amode addr offset $I16) (LoadOP.U16) flags))

;;;;;  Rules for `iload16`;;;;;;;;;
(rule (lower (sload16 flags addr offset))
  (gen_load (amode addr offset $I16) (LoadOP.I16) flags))

;;;;;  Rules for `uload32`;;;;;;;;;
(rule (lower (uload32 flags addr offset))
  (gen_load (amode addr offset $I32) (LoadOP.U32) flags))

;;;;;  Rules for `sload32`;;;;;;;;;
(rule (lower (sload32 flags addr offset))
  (gen_load (amode addr offset $I32) (LoadOP.I32) flags))

;;;;;  Rules for `load`;;;;;;;;;
(rule (lower (has_type ty (load flags addr offset)))
  (gen_load (amode addr offset ty) (load_op ty) flags))

;;;;;  Rules for `istore8`;;;;;;;;;
(rule (lower (istore8 flags src addr offset))
  (gen_store (amode addr offset $I8) (StoreOP.I8) flags src))

;;;;;  Rules for `istore16`;;;;;;;;;
(rule (lower (istore16 flags src addr offset))
  (gen_store (amode addr offset $I16) (StoreOP.I16) flags src))

;;;;;  Rules for `istore32`;;;;;;;;;
(rule (lower (istore32 flags src addr offset))
  (gen_store (amode addr offset $I32) (StoreOP.I32) flags src))

;;;;;  Rules for `store`;;;;;;;;;
(rule (lower (store flags src @ (value_type ty) addr offset))
  (gen_store (amode addr offset ty) (store_op ty) flags src))

(decl gen_icmp (IntCC ValueRegs ValueRegs Type) XReg)
(rule
  (gen_icmp cc x y ty)
  (let
    ((result WritableXReg (temp_writable_xreg))
      (_ Unit (emit (MInst.Icmp cc result x y ty))))
    result))

;;;;;  Rules for `icmp`;;;;;;;;;
(rule 0 (lower (icmp cc x @ (value_type (ty_int ty)) y))
  (lower_icmp cc x y ty))

;;;;;  Rules for `func_addr`;;;;;;;;;
(rule
  (lower (func_addr (func_ref_data _ name _)))
  (load_ext_name name 0))

;;;;;  Rules for `symbol_value`;;;;;;;;;
;; Heap starts at offset 0 in zkAsm machine memory.
(rule 0
   (lower (symbol_value (zkasm_base ZkasmBase.Heap)))
   (imm $I32 0))

(rule 1
   (lower (symbol_value (symbol_value_data name _ offset)))
   (load_ext_name name offset))

;; (rule 1
;;    (lower (symbol_value (zkasm_base ZkasmBase.Table)))
;;    (imm $I32 42))

;;;;;  Rules for `bitcast`;;;;;;;;;
(rule
   (lower (has_type out_ty (bitcast _ v @ (value_type in_ty))))
   (gen_bitcast v in_ty out_ty))

;; N.B.: the Ret itself is generated by the ABI.
(rule (lower (return args))
      (lower_return args))

;;; Rules for `get_{frame,stack}_pointer` and `get_return_address` ;;;;;;;;;;;;;

(rule (lower (get_frame_pointer))
  (gen_mov_from_preg (fp_reg)))

(rule (lower (get_stack_pointer))
  (gen_mov_from_preg (sp_reg)))

(rule (lower (get_return_address))
  (load_ra))

;;; Rules for `iabs` ;;;;;;;;;;;;;

;; I64 and lower
;; Generate the following code:
;;   sext.{b,h,w} a0, a0
;;   neg a1, a0
;;   max a0, a0, a1
; (rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (iabs x)))
;   (let ((extended XReg (sext x ty $I64))
;         (negated XReg (rv_neg extended)))
;     (max $I64 extended negated)))

;;;; Rules for calls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (call (func_ref_data sig_ref extname dist) inputs))
  (gen_call sig_ref extname dist inputs))

(rule (lower (call_indirect sig_ref val inputs))
  (gen_call_indirect sig_ref val inputs))

;;;; Rules for `return_call` and `return_call_indirect` ;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (return_call (func_ref_data sig_ref extname dist) args))
      (gen_return_call sig_ref extname dist args))

(rule (lower (return_call_indirect sig_ref callee args))
      (gen_return_call_indirect sig_ref callee args))
