;; zkasm instruction selection and CLIF-to-MachInst lowering.

;; The main lowering constructor term: takes a clif `Inst` and returns the
;; register(s) within which the lowered instruction's result values live.
(decl partial lower (Inst) InstOutput)

;;;; Rules for `iconst` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type ty (iconst (u64_from_imm64 n))))
  (imm ty n))

;;;; Rules for `f32const` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (f32const (u32_from_ieee32 n)))
  (imm $F32 n))

;;;; Rules for `f64const` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (f64const (u64_from_ieee64 n)))
  (imm $F64 n))

;;;; Rules for `null` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type ty (null)))
  (imm ty 0))


;;;; Rules for `iadd` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; Base case, simply adding things in registers.
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (iadd x y)))
  (rv_add x y))

(rule 1 (lower (iadd (imm32_from_value x) (imm32_from_value y)))
  (zk_add x y))

;; Fused Multiply Accumulate Rules `vmacc`
;;
;; I dont think we can use `vmadd`/`vmnsub` here since it just modifies the multiplication
;; register instead of the addition one. The actual pattern matched seems to be
;; exactly the same.

;;; Rules for `uadd_overflow_trap` ;;;;;;;;;;;;;
(rule
  (lower (has_type (fits_in_64 ty) (uadd_overflow_trap x y tc)))
  (let ((res ValueRegs (lower_uadd_overflow x y ty))
        (_ InstOutput (gen_trapif (value_regs_get res 1) tc)))
    (value_regs_get res 0)))


;;;; Rules for `isub` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;; Base case, simply subtracting things in registers.

(rule (lower (has_type (ty_int_ref_scalar_64 ty) (isub x y)))
  (rv_sub x y))

(rule 1 (lower (has_type (fits_in_32 (ty_int ty)) (isub x y)))
  (rv_subw x y))

(rule 2 (lower (has_type $I128 (isub x y)))
  (i128_sub x y))

;;;; Rules for `ineg` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (has_type (ty_int ty) (ineg val)))
  (neg ty val))

;;;; Rules for `imul` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (imul x y)))
  (rv_mul x y))

(rule 1 (lower (has_type (fits_in_32 (ty_int ty)) (imul x y)))
  (rv_mulw x y))

;; for I128
(rule 2 (lower (has_type $I128 (imul x y)))
  (let
    ((x_regs ValueRegs x)
      (x_lo XReg (value_regs_get x_regs 0))
      (x_hi XReg (value_regs_get x_regs 1))

      ;; Get the high/low registers for `y`.
      (y_regs ValueRegs y)
      (y_lo XReg (value_regs_get y_regs 0))
      (y_hi XReg (value_regs_get y_regs 1))

      ;; 128bit mul formula:
      ;;   dst_lo = x_lo * y_lo
      ;;   dst_hi = mulhu(x_lo, y_lo) + (x_lo * y_hi) + (x_hi * y_lo)
      ;;
      ;; We can convert the above formula into the following
      ;; mulhu   dst_hi, x_lo, y_lo
      ;; madd    dst_hi, x_lo, y_hi, dst_hi
      ;; madd    dst_hi, x_hi, y_lo, dst_hi
      ;; madd    dst_lo, x_lo, y_lo, zero
      (dst_hi1 XReg (rv_mulhu x_lo y_lo))
      (dst_hi2 XReg (madd x_lo y_hi dst_hi1))
      (dst_hi XReg (madd x_hi y_lo dst_hi2))
      (dst_lo XReg (madd x_lo y_lo (zero_reg))))
    (value_regs dst_lo dst_hi)))

;;;; Rules for `smulhi` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (smulhi x y)))
  (lower_smlhi ty (sext x ty $I64) (sext y ty $I64)))

;;;; Rules for `umulhi` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (umulhi x y)))
  (lower_umlhi ty (zext x ty $I64) (zext y ty $I64)))

;;;; Rules for `div` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule -1 (lower (has_type (fits_in_32 ty) (udiv x y)))
  (let
    ((y2 XReg (zext y ty $I64))
      (_ InstOutput (gen_div_by_zero y2)))
    (rv_divuw (zext x ty $I64) y2)))

; (rule -1 (lower (has_type (fits_in_32 ty) (sdiv x y)))
;   (let
;     ((a XReg (sext x ty $I64))
;       (b XReg (sext y ty $I64))
;       (_ InstOutput (gen_div_overflow a b ty))
;       (_ InstOutput (gen_div_by_zero b)))
;     (rv_divw a b)))
;
; (rule (lower (has_type $I64 (sdiv x y)))
;   (let
;     ((_ InstOutput (gen_div_overflow x y $I64))
;       (_ InstOutput (gen_div_by_zero y))    )
;     (rv_div x y)))

(rule (lower (has_type $I64 (udiv x y)))
  (let
    ((_ InstOutput (gen_div_by_zero y)))
    (rv_divu x y)))

;;;; Rules for `rem` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule -1 (lower (has_type (fits_in_16 ty) (urem x y)))
  (let
    ((y2 XReg (zext y ty $I64))
      (_ InstOutput (gen_div_by_zero y2)))
    (rv_remuw (zext x ty $I64) y2)))

(rule -1 (lower (has_type (fits_in_16 ty) (srem x y)))
  (let
    ((y2 XReg (sext y ty $I64))
      (_ InstOutput (gen_div_by_zero y2)))
    (rv_remw (sext x ty $I64) y2)))

(rule (lower (has_type $I32 (srem x y)))
  (let
    ((y2 XReg (sext y $I32 $I64))
      (_ InstOutput (gen_div_by_zero y2)))
   (rv_remw x y2)))

(rule (lower (has_type $I32 (urem x y)))
  (let
    ((y2 XReg (zext y $I32 $I64))
        (_ InstOutput (gen_div_by_zero y2)))
    (rv_remuw x y2)))

(rule (lower (has_type $I64 (srem x y)))
  (let
    ((_ InstOutput (gen_div_by_zero y)))
    (rv_rem x y)))

(rule (lower (has_type $I64 (urem x y)))
  (let
    ((_ InstOutput (gen_div_by_zero y)))
    (rv_remu x y)))

;;;; Rules for `and` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int ty) (band x y)))
  (gen_and ty x y))

(rule 3 (lower (has_type (ty_scalar_float ty) (band x y)))
  (lower_float_binary (AluOPRRR.And) x y ty))

;; Specialized lowerings for `(band x (bnot y))` which is additionally produced
;; by Cranelift's `band_not` instruction that is legalized into the simpler
;; forms early on.

(rule 4 (lower (has_type (fits_in_64 (ty_int ty)) (band x (bnot y))))
  (if-let $true (has_zbb))
  (rv_andn x y))

(rule 5 (lower (has_type (fits_in_64 (ty_int ty)) (band (bnot y) x)))
  (if-let $true (has_zbb))
  (rv_andn x y))

(rule 6 (lower (has_type $I128 (band x (bnot y))))
  (if-let $true (has_zbb))
  (let ((low XReg (rv_andn (value_regs_get x 0) (value_regs_get y 0)))
        (high XReg (rv_andn (value_regs_get x 1) (value_regs_get y 1))))
    (value_regs low high)))

(rule 7 (lower (has_type $I128 (band (bnot y) x)))
  (if-let $true (has_zbb))
  (let ((low XReg (rv_andn (value_regs_get x 0) (value_regs_get y 0)))
        (high XReg (rv_andn (value_regs_get x 1) (value_regs_get y 1))))
    (value_regs low high)))

;;;; Rules for `or` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (ty_int ty) (bor x y)))
  (gen_or ty x y))

(rule 3 (lower (has_type (ty_scalar_float ty) (bor x y)))
  (lower_float_binary (AluOPRRR.Or) x y ty))

;; Specialized lowerings for `(bor x (bnot y))` which is additionally produced
;; by Cranelift's `bor_not` instruction that is legalized into the simpler
;; forms early on.

(rule 4 (lower (has_type (fits_in_64 (ty_int ty)) (bor x (bnot y))))
  (if-let $true (has_zbb))
  (rv_orn x y))

(rule 5 (lower (has_type (fits_in_64 (ty_int ty)) (bor (bnot y) x)))
  (if-let $true (has_zbb))
  (rv_orn x y))

(rule 6 (lower (has_type $I128 (bor x (bnot y))))
  (if-let $true (has_zbb))
  (let ((low XReg (rv_orn (value_regs_get x 0) (value_regs_get y 0)))
        (high XReg (rv_orn (value_regs_get x 1) (value_regs_get y 1))))
    (value_regs low high)))

(rule 7 (lower (has_type $I128 (bor (bnot y) x)))
  (if-let $true (has_zbb))
  (let ((low XReg (rv_orn (value_regs_get x 0) (value_regs_get y 0)))
        (high XReg (rv_orn (value_regs_get x 1) (value_regs_get y 1))))
    (value_regs low high)))

;;;; Rules for `xor` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 0 (lower (has_type (fits_in_64 (ty_int ty)) (bxor x y)))
  (rv_xor x y))

(rule 3 (lower (has_type $I128 (bxor x y)))
  (lower_b128_binary (AluOPRRR.Xor) x y))

(rule 4 (lower (has_type (ty_scalar_float ty) (bxor x y)))
  (lower_float_binary (AluOPRRR.Xor) x y ty))

;;;; Rules for `bit_reverse` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;; Rules for `bswap` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule 1 (lower (has_type (fits_in_64 (ty_int ty)) (bswap x)))
  (gen_bswap ty x))

(rule 2 (lower (has_type $I128 (bswap x)))
  (value_regs
    (gen_bswap $I64 (value_regs_get x 1))
    (gen_bswap $I64 (value_regs_get x 0))))


;;;; Rules for `ctz` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (ctz x)))
  (lower_ctz ty x))

(rule 1 (lower (has_type $I128 (ctz x)))
  (lower_ctz_128 x))

;;;; Rules for `clz` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (clz x)))
  (lower_clz ty x))

(rule 1 (lower (has_type $I128 (clz x)))
  (lower_clz_i128 x))

;;;; Rules for `uextend` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type out_ty (uextend val @ (value_type in_ty))))
  (extend val (ExtendOp.Zero) in_ty out_ty))

;;;; Rules for `sextend` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type out_ty (sextend val @ (value_type in_ty))))
  (extend val (ExtendOp.Signed) in_ty out_ty))

;; The instructions below are present in RV64I and sign-extend the result to 64 bits.

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (iadd x y)))))
  (rv_addw x y))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (isub x y)))))
  (rv_subw x y))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (ishl x y)))))
  (rv_sllw x (value_regs_get y 0)))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (ushr x y)))))
  (rv_srlw x (value_regs_get y 0)))

(rule 1 (lower (has_type $I64 (sextend (has_type $I32 (sshr x y)))))
  (rv_sraw x (value_regs_get y 0)))

;;;; Rules for `popcnt` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;;;; Rules for `ishl` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; 8/16 bit types need a mask on the shift amount
; (rule 0 (lower (has_type (ty_int (ty_8_or_16 ty)) (ishl x y)))
;   (if-let mask (u64_to_imm12 (shift_mask ty)))
;   (rv_sllw x (rv_andi (value_regs_get y 0) mask)))

;; Using the 32bit version of `sll` automatically masks the shift amount.
(rule 1 (lower (has_type $I32 (ishl x y)))
  (rv_sllw x (value_regs_get y 0)))

;; Similarly, the 64bit version does the right thing.
(rule 1 (lower (has_type $I64 (ishl x y)))
  (rv_sll x (value_regs_get y 0)))

; ;; I128 cases
; (rule 4 (lower (has_type $I128 (ishl x y)))
;   (let ((tmp ValueRegs (gen_shamt $I128 (value_regs_get y 0)))
;         (shamt XReg (value_regs_get tmp 0))
;         (len_sub_shamt XReg (value_regs_get tmp 1))
;         ;;
;         (low XReg (rv_sll (value_regs_get x 0) shamt))
;         ;; high part.
;         (high_part1 XReg (rv_srl (value_regs_get x 0) len_sub_shamt))
;         (high_part2 XReg (gen_select_reg (IntCC.Equal) shamt (zero_reg) (zero_reg) high_part1))
;         ;;
;         (high_part3 XReg (rv_sll (value_regs_get x 1) shamt))
;         (high XReg (rv_or high_part2 high_part3))
;         ;;
;         (const64 XReg (load_u64_constant 64))
;         (shamt_128 XReg (rv_andi (value_regs_get y 0) (imm12_const 127))))
;     (value_regs
;       (gen_select_reg (IntCC.UnsignedGreaterThanOrEqual) shamt_128 const64 (zero_reg) low)
;       (gen_select_reg (IntCC.UnsignedGreaterThanOrEqual) shamt_128 const64 low high))))

;;;; Rules for `ushr` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; 8/16 bit types need a mask on the shift amount, and the LHS needs to be
;; zero extended.
; (rule 0 (lower (has_type (ty_int (fits_in_16 ty)) (ushr x y)))
;   (if-let mask (u64_to_imm12 (shift_mask ty)))
;   (rv_srlw (zext x ty $I64) (rv_andi (value_regs_get y 0) mask)))

;; Using the 32bit version of `srl` automatically masks the shift amount.
(rule 1 (lower (has_type $I32 (ushr x y)))
  (rv_srlw x (value_regs_get y 0)))

;; Similarly, the 64bit version does the right thing.
(rule 1 (lower (has_type $I64 (ushr x y)))
  (rv_srl x (value_regs_get y 0)))

; (rule 3 (lower (has_type $I128 (ushr x y)))
;   (let ((tmp ValueRegs (gen_shamt $I128 (value_regs_get y 0)))
;         (shamt XReg (value_regs_get tmp 0))
;         (len_sub_shamt XReg (value_regs_get tmp 1))
;         ;; low part.
;         (low_part1 XReg (rv_sll (value_regs_get x 1) len_sub_shamt))
;         (low_part2 XReg (gen_select_reg (IntCC.Equal) shamt (zero_reg) (zero_reg) low_part1))
;         ;;
;         (low_part3 XReg (rv_srl (value_regs_get x 0) shamt))
;         (low XReg (rv_or low_part2 low_part3))
;         ;;
;         (const64 XReg (load_u64_constant 64))
;         ;;
;         (high XReg (rv_srl (value_regs_get x 1) shamt))
;         (shamt_128 XReg (rv_andi (value_regs_get y 0) (imm12_const 127))))
;     (value_regs
;       (gen_select_reg (IntCC.UnsignedGreaterThanOrEqual) shamt_128 const64 high low)
;       (gen_select_reg (IntCC.UnsignedGreaterThanOrEqual) shamt_128 const64 (zero_reg) high))))

;;;; Rules for `sshr` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

;; 8/16 bit types need a mask on the shift amount, and the LHS needs to be
;; zero extended.
; (rule 0 (lower (has_type (ty_int (fits_in_16 ty)) (sshr x y)))
;   (if-let mask (u64_to_imm12 (shift_mask ty)))
;   (rv_sraw (sext x ty $I64) (rv_andi (value_regs_get y 0) mask)))

;; Using the 32bit version of `sra` automatically masks the shift amount.
(rule 1 (lower (has_type $I32 (sshr x y)))
  (rv_sraw x (value_regs_get y 0)))

;; Similarly, the 64bit version does the right thing.
(rule 1 (lower (has_type $I64 (sshr x y)))
  (rv_sra x (value_regs_get y 0)))

; (rule 3 (lower (has_type $I128 (sshr x y)))
;   (let ((tmp ValueRegs (gen_shamt $I128 (value_regs_get y 0)))
;         (shamt XReg (value_regs_get tmp 0))
;         (len_sub_shamt XReg (value_regs_get tmp 1))
;         ;; low part.
;         (low_part1 XReg (rv_sll (value_regs_get x 1) len_sub_shamt))
;         (low_part2 XReg (gen_select_reg (IntCC.Equal) shamt (zero_reg) (zero_reg) low_part1))
;         ;;
;         (low_part3 XReg (rv_srl (value_regs_get x 0) shamt))
;         (low XReg (rv_or low_part2 low_part3))
;         ;;
;         (const64 XReg (load_u64_constant 64))
;         ;;
;         (high XReg (rv_sra (value_regs_get x 1) shamt))
;         ;;
;         (const_neg_1 XReg (load_imm12 -1))
;         ;;
;         (high_replacement XReg (gen_select_reg (IntCC.SignedLessThan) (value_regs_get x 1) (zero_reg) const_neg_1 (zero_reg)))
;         (const64 XReg (load_u64_constant 64))
;         (shamt_128 XReg (rv_andi (value_regs_get y 0) (imm12_const 127))))
;     (value_regs
;       (gen_select_reg (IntCC.UnsignedGreaterThanOrEqual) shamt_128 const64 high low)
;       (gen_select_reg (IntCC.UnsignedGreaterThanOrEqual) shamt_128 const64 high_replacement high))))

;;;; Rules for `rotl` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (rotl x y)))
  (lower_rotl ty (zext x ty $I64) (value_regs_get y 0)))

; (rule 1 (lower (has_type $I128 (rotl x y)))
;   (lower_i128_rotl x y))

;;;; Rules for `rotr` ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
(rule (lower (has_type (fits_in_64 ty) (rotr x y)))
  (lower_rotr ty (zext x ty $I64) (value_regs_get y 0)))

; (rule 1 (lower (has_type $I128 (rotr x y)))
;   (lower_i128_rotr x y))

;;;;;  Rules for `ireduce`;;;;;;;;;;;;;;;;;
(rule
  (lower (has_type ty (ireduce x)))
  (value_regs_get x 0))

;;;;;  Rules for `stack_addr`;;;;;;;;;
(rule
  (lower (stack_addr ss offset))
  (gen_stack_addr ss offset))

;;;;;  Rules for `is_null`;;;;;;;;;

;; Null references are represented by the constant value `0`.
; (rule (lower (is_null v))
;   (rv_seqz v))

;;;;;  Rules for `is_invalid`;;;;;;;;;

;; Invalid references are represented by the constant value `-1`.
; (rule (lower (is_invalid v))
;   (rv_seqz (rv_addi v (imm12_const 1))))

;;;;;  Rules for `select`;;;;;;;;;
(rule
  (lower (has_type ty (select c @ (value_type cty) x y)))
  (gen_select ty (truthy_to_reg cty (normalize_cmp_value cty c (ExtendOp.Zero))) x y))

(rule 1
  (lower (has_type (fits_in_64 ty) (select (icmp cc a b @ (value_type (fits_in_64 in_ty))) x y)))
  (let ((a XReg (truthy_to_reg in_ty (normalize_cmp_value in_ty a (intcc_to_extend_op cc))))
        (b XReg (truthy_to_reg in_ty (normalize_cmp_value in_ty b (intcc_to_extend_op cc)))))
    (gen_select_reg cc a b x y)))

;;;;;  Rules for `bitselect`;;;;;;;;;

;; Do a (c & x) | (~c & y) operation.
; (rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (bitselect c x y)))
;   (let ((tmp_x XReg (rv_and c x))
;         (c_inverse XReg (rv_not c))
;         (tmp_y XReg (rv_and c_inverse y)))
;     (rv_or tmp_x tmp_y)))

;;;;;  Rules for `isplit`;;;;;;;;;
(rule
  (lower (isplit x))
  (let
    ((t1 XReg (value_regs_get x 0))
      (t2 XReg (value_regs_get x 1)))
    (output_pair t1 t2)))

;;;;;  Rules for `iconcat`;;;;;;;;;
(rule
  (lower (has_type $I128 (iconcat x y)))
  (let
    ((t1 XReg x)
      (t2 XReg y))
    (value_regs t1 t2)))


;;;;;  Rules for `smax`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty)  (smax x y)))
  (gen_int_select ty (IntSelectOP.Smax) (ext_int_if_need $true x ty) (ext_int_if_need $true y ty)))

;;;;;  Rules for `smin`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty)  (smin x y)))
  (gen_int_select ty (IntSelectOP.Smin) (ext_int_if_need $true x ty) (ext_int_if_need $true y ty)))

;;;;;  Rules for `umax`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty)  (umax x y)))
  (gen_int_select ty (IntSelectOP.Umax) (ext_int_if_need $false x ty) (ext_int_if_need $false y ty)))

;;;;;  Rules for `umin`;;;;;;;;;

(rule 0 (lower (has_type (ty_int ty) (umin x y)))
  (gen_int_select ty (IntSelectOP.Umin) (ext_int_if_need $false x ty) (ext_int_if_need $false y ty)))

;;;;;  Rules for `debugtrap`;;;;;;;;;
(rule
  (lower (debugtrap))
  (side_effect (SideEffectNoResult.Inst (MInst.EBreak))))

;;;;;  Rules for `trap`;;;;;;;;;
(rule
  (lower (trap code))
  (udf code))

;;;;;  Rules for `resumable_trap`;;;;;;;;;
(rule
  (lower (resumable_trap code))
  (udf code))

;;;;;  Rules for `uload8`;;;;;;;;;
(rule
  (lower (uload8 flags p @ (value_type (ty_addr64 _)) offset))
  (gen_load p offset (int_load_op $false 8) flags $I64))
;;;;;  Rules for `sload8`;;;;;;;;;
(rule
  (lower (sload8 flags p @ (value_type (ty_addr64 _)) offset))
  (gen_load p offset (int_load_op $true 8) flags $I64))
;;;;;  Rules for `uload16`;;;;;;;;;
(rule
  (lower (uload16 flags p @ (value_type (ty_addr64 _)) offset))
  (gen_load p offset (int_load_op $false 16) flags $I64))

;;;;;  Rules for `iload16`;;;;;;;;;
(rule
  (lower (sload16 flags p @ (value_type (ty_addr64 _)) offset))
  (gen_load p offset (int_load_op $true 16) flags $I64))

;;;;;  Rules for `uload32`;;;;;;;;;
(rule
  (lower (uload32 flags p @ (value_type (ty_addr64 _)) offset))
  (gen_load p offset (int_load_op $false 32) flags $I64))

;;;;;  Rules for `iload32`;;;;;;;;;
(rule
  (lower (sload32 flags p @ (value_type (ty_addr64 _)) offset))
  (gen_load p offset (int_load_op $true 32) flags $I64))

(rule
  (lower (has_type ty (load flags p @ (value_type (ty_addr32 _)) offset)))
  (gen_load p offset (load_op ty) flags ty)
)
;;;; for I128
(rule 1
  (lower (has_type $I128 (load flags p @ (value_type (ty_addr64 _)) offset)))
  (gen_load_128 p offset flags))

;;;;;  Rules for `istore8`;;;;;;;;;
(rule
  (lower (istore8 flags x p @ (value_type (ty_addr64 _)) offset))
  (gen_store p offset (StoreOP.Sb) flags x))
;;;;;  Rules for `istore16`;;;;;;;;;
(rule
  (lower (istore16 flags x p @ (value_type (ty_addr64 _)) offset))
  (gen_store p offset (StoreOP.Sh) flags x))

;;;;;  Rules for `istore32`;;;;;;;;;
(rule
  (lower (istore32 flags x p @ (value_type (ty_addr64 _)) offset))
  (gen_store p offset (StoreOP.Sw) flags x))

;;;;;  Rules for `store`;;;;;;;;;
(rule
  (lower (store flags x @ (value_type ty) p @ (value_type (ty_addr32 _)) offset))
  (gen_store p offset (store_op ty) flags x))

;;; special for I128
(rule 1
  (lower (store flags x @ (value_type $I128 ) p @ (value_type (ty_addr64 _)) offset))
  (gen_store_128 p offset flags x))

(decl gen_icmp (IntCC ValueRegs ValueRegs Type) XReg)
(rule
  (gen_icmp cc x y ty)
  (let
    ((result WritableXReg (temp_writable_xreg))
      (_ Unit (emit (MInst.Icmp cc result x y ty))))
    result))

;;;;;  Rules for `icmp`;;;;;;;;;
(rule 0 (lower (icmp cc x @ (value_type (ty_int ty)) y))
  (lower_icmp cc x y ty))

;;;;;  Rules for `func_addr`;;;;;;;;;
(rule
  (lower (func_addr (func_ref_data _ name _)))
  (load_ext_name name 0))

;;;;;  Rules for `symbol_value`;;;;;;;;;
(rule
   (lower (symbol_value (symbol_value_data name _ offset)))
   (load_ext_name name offset)
)
;;;;;  Rules for `bitcast`;;;;;;;;;
(rule
   (lower (has_type out_ty (bitcast _ v @ (value_type in_ty))))
   (gen_bitcast v in_ty out_ty))

;;;;;  Rules for `bmask`;;;;;;;;;
(rule
  (lower (has_type oty (bmask x @ (value_type ity))))
  (lower_bmask oty ity x))

;; N.B.: the Ret itself is generated by the ABI.
(rule (lower (return args))
      (lower_return args))

;;; Rules for `get_{frame,stack}_pointer` and `get_return_address` ;;;;;;;;;;;;;

(rule (lower (get_frame_pointer))
  (gen_mov_from_preg (fp_reg)))

(rule (lower (get_stack_pointer))
  (gen_mov_from_preg (sp_reg)))

(rule (lower (get_return_address))
  (load_ra))

;;; Rules for `iabs` ;;;;;;;;;;;;;

;; I64 and lower
;; Generate the following code:
;;   sext.{b,h,w} a0, a0
;;   neg a1, a0
;;   max a0, a0, a1
(rule 0 (lower (has_type (ty_int_ref_scalar_64 ty) (iabs x)))
  (let ((extended XReg (sext x ty $I64))
        (negated XReg (rv_neg extended)))
    (max $I64 extended negated)))

;;;; Rules for calls ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (call (func_ref_data sig_ref extname dist) inputs))
  (gen_call sig_ref extname dist inputs))

(rule (lower (call_indirect sig_ref val inputs))
  (gen_call_indirect sig_ref val inputs))

;;;; Rules for `return_call` and `return_call_indirect` ;;;;;;;;;;;;;;;;;;;;;;;;

(rule (lower (return_call (func_ref_data sig_ref extname dist) args))
      (gen_return_call sig_ref extname dist args))

(rule (lower (return_call_indirect sig_ref callee args))
      (gen_return_call_indirect sig_ref callee args))
